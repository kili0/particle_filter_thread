# -*- coding: utf-8 -*-
"""particle_filter_class.ipynb のコピー

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17VdA1Di-ZJpi2duFKk-1C6fOtqbn375j
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import numpy.random as rd
import pandas as pd
import time

import matplotlib
from matplotlib import font_manager
import matplotlib.pyplot as plt
# import seaborn as sns

from concurrent.futures import ThreadPoolExecutor
from logging import StreamHandler, Formatter, INFO, getLogger
import time

def init_logger():
    handler = StreamHandler()
    handler.setLevel(INFO)
    handler.setFormatter(Formatter("[%(asctime)s] [%(threadName)s] %(message)s"))
    logger = getLogger()
    logger.addHandler(handler)
    logger.setLevel(INFO)

# sns.set(style="whitegrid", palette="muted", color_codes=True)

# 直接読み込む場合
df = pd.read_csv("http://daweb.ism.ac.jp/yosoku/materials/PF-example-data.txt", header=None)

df.columns = ["data"]

df.plot(figsize=(12,4))
plt.title("Test Data")

class ParticleFilter(object):
    def __init__(self, y, n_particle, sigma_2, alpha_2):
        self.y = y
        self.n_particle = n_particle
        self.sigma_2 = sigma_2
        self.alpha_2 = alpha_2
        self.log_likelihood = -np.inf

    def norm_likelihood(self, y, x, s2):
        return (np.sqrt(2*np.pi*s2))**(-1) * np.exp(-(y-x)**2/(2*s2))

    def F_inv(self, w_cumsum, idx, u):
            if np.any(w_cumsum < u) == False:
                return 0
            k = np.max(idx[w_cumsum < u])
            return k+1

    def resampling2(self, weights):
        """
        計算量の少ない層化サンプリング
        """
        idx = np.asanyarray(range(self.n_particle))
        u0 = rd.uniform(0, 1/self.n_particle)
        u = [1/self.n_particle*i + u0 for i in range(self.n_particle)]
        w_cumsum = np.cumsum(weights)
        # print("  w_cumsum:", w_cumsum)
        k = np.asanyarray([self.F_inv(w_cumsum, idx, val) for val in u])
        return k

    def simulate(self, seed=71):
        rd.seed(seed)

        # 時系列データ数
        T = len(self.y)

        # 潜在変数
        x = np.zeros((T+1, self.n_particle))
        x_resampled = np.zeros((T+1, self.n_particle))

        # 潜在変数の初期値
        initial_x = rd.normal(0, 1, size=self.n_particle)
        x_resampled[0] = initial_x
        x[0] = initial_x

        # 重み
        w        = np.zeros((T, self.n_particle))
        w_normed = np.zeros((T, self.n_particle))

        l = np.zeros(T) # 時刻毎の尤度

        # for t in range(T):
        #     # print("\r calculating... t={}".format(t), "\n", end="")
        #     with ThreadPoolExecutor(max_workers=max_thread_num, thread_name_prefix="thread") as executor:
        #         for i in range(max_thread_num):
        #             executor.submit(self.calculation, i, t, x, x_resampled, w, w_normed, l)
        #         # for i in range(n_particle):
        #         #     executor.submit(self.calculation2, i, t, x, x_resampled, w, w_normed, l)
        #     w_normed[t] = w[t]/np.sum(w[t]) # 規格化
        #     l[t] = np.log(np.sum(w[t])) # 各時刻対数尤度

        #     # Resampling
        #     k = self.resampling2(w_normed[t]) # リサンプルで取得した粒子の添字（層化サンプリング）
        #     x_resampled[t+1] = x[t+1, k]

        with ThreadPoolExecutor(max_workers=max_thread_num, thread_name_prefix="thread") as executor:
            for t in range(T):
                for i in range(max_thread_num):
                    executor.submit(self.calculation, i, t, x, x_resampled, w, w_normed, l)

                print("w[", t, "]: ", w[t])
                print("w_sum: ", np.sum(w[t]))
                w_normed[t] = w[t]/np.sum(w[t]) # 規格化
                l[t] = np.log(np.sum(w[t])) # 各時刻対数尤度
                print("w_normed[", t, "]: ", w_normed[t])


                # Resampling
                k = self.resampling2(w_normed[t]) # リサンプルで取得した粒子の添字（層化サンプリング）
                x_resampled[t+1] = x[t+1, k]

        # 全体の対数尤度
        self.log_likelihood = np.sum(l) - T*np.log(n_particle)

        self.x = x
        self.x_resampled = x_resampled
        self.w = w
        self.w_normed = w_normed
        self.l = l

    def calculation(self, th_num, t, x, x_resampled, w, w_normed, l):
        start = int(width * th_num)
        end = int(width * (th_num + 1) -1)
        getLogger().info("%s start", t)
        for i in range(start, end):
          # 1階差分トレンドを適用
          v = rd.normal(0, np.sqrt(self.alpha_2*self.sigma_2)) # System Noise
          x[t+1, i] = x_resampled[t, i] + v # システムノイズの付加
          w[t, i] = self.norm_likelihood(self.y[t], x[t+1, i], self.sigma_2) # y[t]に対する各粒子の尤度
        getLogger().info("%s end", t)

    def calculation2(self, p_num, t, x, x_resampled, w, w_normed, l):
        # getLogger().info("%s start", p_num)
        # 1階差分トレンドを適用
        v = rd.normal(0, np.sqrt(self.alpha_2*self.sigma_2)) # System Noise
        x[t+1, p_num] = x_resampled[t, p_num] + v # システムノイズの付加
        w[t, p_num] = self.norm_likelihood(self.y[t], x[t+1, p_num], self.sigma_2) # y[t]に対する各粒子の尤度
        # getLogger().info("%s end", p_num)


    def get_filtered_value(self):
        """
        尤度の重みで加重平均した値でフィルタリングされ値を算出
        """
        return np.diag(np.dot(self.w_normed, self.x[1:].T))

    def draw_graph(self):
        # グラフ描画
        T = len(self.y)

        plt.figure(figsize=(16,8))
        plt.plot(range(T), self.y)
        plt.plot(self.get_filtered_value(), "g")

        for t in range(T):
            plt.scatter(np.ones(self.n_particle)*t, self.x[t], color="r", s=2, alpha=0.1)

        plt.title("sigma^2={0}, alpha^2={1}, log likelihood={2:.3f}".format(self.sigma_2,
                                                                                 self.alpha_2,
                                                                                 self.log_likelihood))
        #plt.show()

"""### パーティクルフィルターによるフィルタリング"""

# ハイパーパラメーター
a = -2
b = -1

n_particle = 12
# n_particle = 10 ** 5
sigma_2 = 2**a
alpha_2 = 10**b

max_thread_num = 1
width = int(n_particle / max_thread_num)

init_logger()
getLogger().info("main start")
pf = ParticleFilter(df.data.values, n_particle, sigma_2, alpha_2)

start = time.time()
pf.simulate()
stop = time.time()
print('%.3f seconds' % (stop - start))
getLogger().info("main end")

# pf.draw_graph()
